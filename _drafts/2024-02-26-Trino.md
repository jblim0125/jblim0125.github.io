# Trino

## Overview

### Usecase

트리노는 분산 쿼리를 사용하여 방대한 양의 데이터를 효율적으로 쿼리하도록 설계된 도구  
Trino는 Hive 또는 Pig와 같은 MapReduce 작업의 파이프라인을 사용하여 HDFS를 쿼리하는 도구의 대안으로 설계.  
전통적인 관계형 데이터베이스와 카산드라와 같은 다른 데이터 소스를 포함하여 다양한 종류의 데이터 소스를 운영할 수 있도록 확장되었다.  

### Concept

핵심 개념에 대한 정의

1. Architecture  
여러 서버에서 병렬로 데이터를 처리하는 분산 쿼리 엔진이다.
코디네이터, 워커 2가지 유형이 있다.  
A. Cluster
클러스터는 코디네이터와 많은 워커로 구성된다.  
사용자는 SQL 쿼리를 코디네이터로 요청.  
**코디네이터는 워커들과 협력하여 연결된 데이터소스에 접근한다**  
B. Coordinator  
구문 분석, 쿼리 계획, 트리노 워커 노드 관리를 담당하는 서버  
코디네이터는 REST API를 사용하여 워커 및 사용자와 통신  
C. Worker  
작업을 실행하고 데이터를 처리  
워커노드는 커넥터를 이용해 데이터를 가져오고 서로 중간 데이터를 교환한다.
코디네이터는 워커로부터 결과를 가져오고 최종 결과를 사용자에게 반환/책임이 있다.  
워커는 REST API를 사용하여 다른 워커 및 트리노 코디네이터와 소통합니다.
2. Data sources  
A. Connector  
커넥터는 트리노를 다양한 데이터 소스에 연결될 수 있도록 한다.  
데이터베이스 드라이버와 같은 방식으로 커넥터를 생각할 수 있습니다.  
내장 커넥터 : JMX용 커넥터, 내장 시스템 테이블에 대한 액세스를 제공하는 시스템 커넥터, 하이브 커넥터, TPCH 커넥터.  
개발자들은 트리노가 다양한 데이터 소스의 데이터에 접근할 수 있도록 커넥터에 기여했다.  
(커넥터는 카탈로그와 관련이 있다. 카탈로그 구성 파일을 확인하면 커넥터를 만드는 데
사용하는 필수 속성 `connector.name` 이 포함되어 있음을 알 수 있습니다.
하나 이상의 카탈로그가 동일한 커넥터를 사용하여 데이터베이스에 액세스할 수 있습니다.  
예를 들어, 두 개의 하이브 클러스터가 있는 경우, 두 개의 카탈로그를 구성하거나,
하나의 SQL 쿼리 내에서 두 하이브 클러스터에 데이터를 쿼리할 수 있습니다)  

B. Catalog  
트리노 카탈로그는 스키마를 포함하고 커넥터를 통해 데이터 소스를 참조한다.
예를 들어, JMX 커넥터를 통해 JMX 정보에 대한 액세스를 제공하도록 JMX 카탈로그를 구성할 수 있습니다.
트리노에서 SQL 문을 실행할 때, 하나 이상의 카탈로그에 대해 실행하고 있습니다.
카탈로그의 다른 예로는 하이브 데이터 소스에 연결하기 위한 하이브 카탈로그가 있다.
When addressing a table in Trino, the fully-qualified table name is always rooted in a catalog. For example, a fully-qualified table name of hive.test_data.test refers to the test table in the test_data schema in the hive catalog.
카탈로그는 트리노 구성 디렉토리에 저장된 속성 파일에 정의됩니다.
C. Schema  
스키마는 테이블을 정의하는 방법이다. 카탈로그와 스키마는 함께 쿼리할 수 있는 테이블 세트를 정의합니다.
Trino로 Hive 또는 MySQL과 같은 관계형 데이터베이스에 액세스할 때, 스키마는 대상
데이터베이스에서와 동일한 개념으로 변환됩니다.
다른 유형의 커넥터는 기본 데이터 소스에 적합한 방식으로 구성하도록 선택할 수 있습니다.  
오브젝트스토리지의 경우  
파일서버의 경우  
D. Table  
테이블은 유형이 있는 명명된 열로 구성된 정렬되지 않은 행의 집합이다.  
이것은 모든 관계형 데이터베이스와 동일합니다. 소스 데이터에서 테이블로의 매핑은 커넥터에 의해 정의  
3. Query execution model  
트리노는 SQL 문을 실행하고 이 문을 쿼리로 바꾸며, 이는 코디네이터와 작업자의 분산된 클러스터에서 실행된다.  
A. Statement  
트리노는 ANSI 호환 SQL 문을 실행한다.  
B. Query  
Statement와 Query의 차이는 간단하다.  
Statement 트리노에 전달되는 SQL 텍스트
Query 워커노드에서 실행될 수 있도록 인스턴스화된 구성 및 구성 요소의 집합  
(Stage, Task, Split, Connector 및 기타 구성 요소와 데이터 소스를 포함)  
C. Stage  
쿼리는 다시 stage로 분할되는데 계층 구조로 나눠진다.  
예를 들어 데이터를 집계해야 하는 경우, 다른 여러 단계의 출력을 집계하기 위해 루트 단계를 생성해 처리한다.  
Stage 자체는 트리노 워커에서 실행되지 않습니다.
D. Task  
Stage는 Task로 분할되어 실제로 Worker에서 실행이 된다.
E. Split  
F. Driver  
트리노의 데이터 처리 구조에서 가장 낮은 수준의 병렬로 드라이버는 하나의 입력과 하나의 출력을 가지고 있다.
Task에는 하나 이상의 병렬 드라이버가 포함되어 있습니다. Driver는 데이터에 따라 Operator 를 결합하여 동작한다.  
G. Operator  
데이터를 소비하고, 변환하고, 생산한다. 예를 들어, 테이블 스캔은 커넥터에서 데이터를 가져오고 다른 연산자가
소비할 수 있는 데이터를 생성하며, 필터 연산자는 데이터를 소비하고 입력 데이터에 조건자를 적용하여 하위 집합을 생성합니다.  
H. Exchange  
쿼리의 다른 Stage를 위해 트리노 노드 간에 데이터를 전송합니다. Task는 데이터를 출력 버퍼로 생성하고
교환 클라이언트를 사용하여 다른 작업의 데이터를 소비합니다.

## Install

Docker, K8S, RPM 등 다양한 방법으로 실행 가능  
자세한 내용은 생략  

## Client

Trino 는 기본적으로 2가지 인터페이스를 제공 - 명령줄 인터페이스, JDBC 드라이버  
또한, 외부 커뮤니티에서 개발된 파이썬과 같은 플랫폼에서 사용할 수 있는 수많은 다른 클라이언트를 제공.

### JDBC 드라이버  

1. 요구사항  
Java 8 버전 이상  
2. 설치  
Maven에서 드라이버 사용 방법  

    ```xml
    <dependency>
        <groupId>io.trino</groupId>
        <artifactId>trino-jdbc</artifactId>
        <version>439</version>
    </dependency>
    ```

3. 연결  
    연결은 다음과 같이 TrinoURL/[카탈로그]/[스키마] 형태로 설정할 수 있다.  

    ```text
    jdbc:trino://host:port
    jdbc:trino://host:port/catalog
    jdbc:trino://host:port/catalog/schema
    ```

4. 연결 설정  
`DriverManager`를 이용해 환경설정이 가능하다.  

    ```java
    // properties
    String url = "jdbc:trino://example.net:8080/hive/sales";
    Properties properties = new Properties();
    properties.setProperty("user", "test");
    properties.setProperty("password", "secret");
    properties.setProperty("SSL", "true");
    Connection connection = DriverManager.getConnection(url, properties);

    // URL parameters
    String url = "jdbc:trino://example.net:8443/hive/sales?user=test&password=secret&SSL=true";
    Connection connection = DriverManager.getConnection(url);
    ```

주요 옵션  

|이름|설명|
|---|---|
|user|인증 및 인증에 사용할 사용자 이름|
|password|LDAP 인증에 사용할 비밀번호|
|clientInfo|고객에 대한 추가 정보|
|clientTags|리소스 그룹을 선택하기 위한 클라이언트 태그. 예시:abc,xyz|
|traceToken|시스템 전반에 걸쳐 요청을 연관시키는 추적 토큰|
|source|Source name for the Trino query. This parameter should be used in preference to ApplicationName. Thus, it takes precedence over ApplicationName and/or applicationNamePrefix|
|applicationNamePrefix|Prefix to append to any specified ApplicationName client info property, which is used to set the source name for the Trino query if the source parameter has not been set. If neither this property nor ApplicationName or source are set, the source name for the query is trino-jdbc|
|roles|카탈로그와 역할에 대한 키-값 쌍의 목록으로 지정된 카탈로그에 사용할 권한 부여 역할. 예를 들어, catalog1:roleA;catalog2:roleB catalog1 대한 roleA catalog2 대한 roleB 설정합니다.|
|sessionProperties|Session properties to set for the system and for catalogs, specified as a list of key-value pairs. For example, abc:xyz;example.foo:bar sets the system property abc to the value xyz and the foo property for catalog example to the value bar.|
|disableCompression|압축을 활성화해야 하는지 여부.|
|timezone|전달된 시간대를 사용하여 세션의 시간대를 설정합니다. 기본값은 JDBC 드라이버를 실행하는 JVM의 시간대입니다.|
|explicitPrepare|Defaults to true. When set to false, prepared statements are executed calling a single EXECUTE IMMEDIATE query instead of the standard PREPARE <statement> followed by EXECUTE <statement>. This reduces network overhead and uses smaller HTTP headers and requires Trino 431 or greater.|

## Security

## Adminstration  

Trino 관리  

Trino 관리는 웹 UI를 이용해 가능함


### Properties  

Trino 환경 설정  

#### Catalog Management  

- catalog.management  
  - Type : String  
  - Value : `static`, `dynamic`  
  - Default : `static`  
  이 값이 `static`인 경우 trino 서버의 기동 시 catalog 설정을 파일이나 시작 파라미터로부터 로드되며,
  `dynamic` 으로 설정하는 경우 `CREATE CATALOG` 와 `DROP CATALOG`를 이용해 제어할 수 있다.  
  > warning!
  > 실험적인 기능이며, 보안의 영향으로 변경될 수 있으며 버전 호환 문제 발생 가능
  > 일부 커넥터의 경우 카탈로그 삭제 시 리소스 해제되지 않는 문제가 있다.
  > hive, iceberg, delta lake, hudi / HDFS, S3, GCS or Azure 클라우드의 데이터 저장소 커넥터  

- catalog.store  
  - Type : String  
  - Value : `file`, `memory`  
  - Default : `file`  
  카탈로그 정보를 파일 혹은 메모리로 관리한다.  

- catalog.config-dir  
  - Type : String
  - Default : `etc/catalog/`  
  카탈로그 정보 파일을 저장하거나 불러올 위치  

- catalog.disabled-catalogs  
  - Type: String  
  쉼표를 이용해 구분 가능한 카탈로그 이름 리스트로 로드하지 않아야하는 카탈로그 리스트 정보  

#### Spilling  

메모리와 디스크 사용과 관련된 옵션  

#### Exchange  

워커 노드 간 데이터 교환 옵션  
데이터 교환 스레드 수, 암호화 코덱, 버퍼 사이즈, 동시 처리 수

#### Task

작업과 관련된 옵션
CPU, Thread, HTTP Timeout Thread, Task당 Driver 수 등  

#### Write Partitioning  

...

#### Writer Scaling  

...

#### Node Scheduler  

- node-scheduler.include-coordinator  
  - Type : boolean
  - Default : true
  단일 노드를 이용해 코디네이터와 워커를 구성할 수 있도록 해주는 옵션

#### Optimizer  

최적화

#### Logging  

로그 설정  
로그 출력 레벨, 로그 저장 위치

#### Web UI

웹 UI 환경 설정  

#### Regular Expression Function  

정규 표현식에 사용할 라이브러리와 각 라이브러리 설정  

#### HTTP Client

Trino - 사용자 HTTP 연결 간의 설정  

### Spill To Disk

대용량의 메모리가 필요한 작업의 경우, 트리노는 중간 작업 결과를 디스크로 오프로드할 수 있다.  
이 메커니즘의 목표는 쿼리당 또는 노드 제한을 초과하는 메모리가 필요한 쿼리를 실행할 수 있도록 하는 것

### Resource Groups

리소스 그룹은 리소스 사용을 제한하고, 그룹 내에서 실행되는 쿼리에 대해 대기열 정책을 시행하거나 하위 그룹 간에 리소스를 나눌 수 있습니다. 쿼리는 단일 리소스 그룹에 속하며, 그 그룹(부모 그룹)의 리소스를 소비합니다.  
리소스 그룹이 리소스가 부족하더라도 실행 중인 쿼리는 실패하지 않습니다. 대신 새로운 쿼리가 실행되지 않고 대기 상태로(대기열) 있습니다.  
리소스 그룹은 쿼리를 받아 실행하게 하거나 하위 그룹으로 나눠 하위 그룹에서 쿼리를 받아 실행할 수 있도록 할 수 있습니다.
쿼리 실행과 하위 그룹 모두를 설정할 수는 없습니다.

리소스 그룹 관리는 파일 또는 데이터베이스 기반으로 설정할 수 있습니다.  

### Session Property Managers

세션 기반으로 쿼리 작업을 제어할 수 있음.  
사용자, 쿼리 타입, 리소스 그룹, ...

### Distributed Sort

분산 정렬 옵션  

### Dynamic Filtering

...

### Graceful Shutdown

워커의ㅎGraceful Shutdown 기능을 제공
API 호출로 워커를 종료할 수 있음.  

### Fault-Tolerant Execution

기본적으로, 트리노 노드가 작업을 실행할 리소스가 부족하거나 쿼리 실행 중에 실패하면 쿼리가 실패하고 수동으로 다시 실행해야 합니다. 쿼리의 런타임이 길수록, 그러한 실패에 취약할 가능성이 높아진다.  

내결함성 실행은 실패 시 쿼리 또는 구성 요소 작업을 다시 시도하여 클러스터가 쿼리 실패를 완화할 수 있도록 하는 트리노의 메커니즘입니다. 내결함성 실행이 활성화되면 중간 교환 데이터가 스풀링되고 쿼리 실행 중 워커의 비정상 종료 또는 기타 오류가 발생할 경우 다른 워커가 재사용할 수 있습니다.
[설정방법](https://trino.io/docs/current/installation/query-resiliency.html)  

### HTTP Event Listener

HTTP 이벤트 리스너 플러그인은 JSON 형식으로 인코딩된 쿼리 이벤트를 지정된 URI로 POST하여 추가 처리를 위해 외부 서비스로 스트리밍할 수 있습니다.

1. Setup  
    `etc` 디렉토리에 `http-event-listener.properties` 이름의 파일 생성  

    ```text
    event-listener.name=http
    http-event-listener.log-created=true
    http-event-listener.connect-ingest-uri=<your ingest URI>
    ```

    `event-listener.config-files` 에 `etc/http-event-listener.properties` 파일 위치 설정  

    ```text
    event-listener.config-files=etc/http-event-listener.properties,...
    ```

2. Options  

    |Property Name|Description|Default|
    |---|---|---|
    |http-event-listener.log-created|`QueryCreatedEvent` 이벤트 로그 활성화|false|
    |http-event-listener.log-created|`QueryCompletedEvent` 이벤트 로그 활성화|false|
    |http-event-listener.log-created|`SplitCompletedEvent` 이벤트 로그 활성화|false|
    |http-event-listener.connect-ingest-uri| 이벤트를 수신할 URI 정보 | None |
    |http-event-listener.http-headers| 이벤트 수신 시 메시지 헤더에 추가할 메시지 | Empty |
    |http-event-listener.connect-retry-count| 재전송 횟수 | 0 |
    |http-event-listener.connect-retry-delay | 재전송 대기 시간 | 1s |
    |http-event-listener.connect-backoff-base | 재전송 시 대기 시간 (=retryDelay * backoffBase^attemptCount) | 2 |

### MySQL Event Listener

MySQL 이벤트 리스너 플러그인을 사용하면 쿼리 이벤트를 외부 MySQL 데이터베이스로 스트리밍할 수 있습니다. 그런 다음 데이터베이스의 쿼리 기록은 MySQL에서 직접 액세스하거나 MySQL 커넥터를 사용하여 Trino의 카탈로그를 통해 액세스할 수 있습니다.

## Query Optimizer

### Table statistics

트리노는 쿼리에 대한 통계 기반 최적화를 지원합니다. 쿼리가 이러한 최적화를 활용하려면, 트리노는 해당 쿼리의 테이블에 대한 통계 정보가 있어야 합니다.

테이블 통계는 커넥터에 의해 쿼리 플래너에 제공됩니다.

#### 이용 가능한 통계

다음 통계는 트리노에서 사용할 수 있습니다:

- 테이블 데이터  
  - row count  
- 테이블 데이터의 각 열에 대해  
  - data size  
  - nulls fraction : null 분포?
  - distinct value count  
  - low value : 컬럼에서 제일 작은 값  
  - high value : 컬럼에서 제일 큰 값  

특정 쿼리에 사용할 수 있는 통계 세트는 사용 중인 커넥터에 따라 다르며 테이블에 따라 다를 수도 있습니다.  
예를 들어, 하이브 커넥터는 현재 데이터 크기에 대한 통계를 제공하지 않는다.  
테이블 통계는 SHOW STATS 명령을 사용하여 Trino SQL 인터페이스를 통해 표시할 수 있습니다. 하이브 커넥터의 경우, 테이블 통계를 업데이트하는 방법을 배우려면 하이브 커넥터 문서를 참조하십시오.

### Cost in EXPLAIN

...

### Cost-based optimizations

...

### Pushdown

트리노는 쿼리 처리 또는 쿼리의 일부를 연결된 데이터 소스로 밀어 넣을 수 있다. 이것은 특정 조건자, 집계 기능 또는 기타 작업이 처리를 위해 기본 데이터베이스 또는 스토리지 시스템으로 전달된다는 것을 의미합니다.

이 푸시다운의 결과는 다음과 같은 이점을 포함할 수 있다:

- 전반적인 쿼리 성능 향상
- 트리노와 데이터 소스 간의 네트워크 트래픽 감소
- 원격 데이터 소스의 부하 감소

이러한 혜택은 종종 상당한 비용 절감을 초래한다.
푸시다운에 대한 지원은 각 커넥터와 관련 기본 데이터베이스 또는 스토리지 시스템에 따라 다릅니다.  

## Connectors

Trino에서 지원하는 데이터 소스  

- Accumulo  
Apache Accumulo 의 데이터 읽기/쓰기 지원  
- Atop  
Atop Linux 서버 성능 분석 도구에서 디스크 사용률 통계 읽기 지원  
The connector can read disk utilization statistics on the Trino cluster.  
- BigQuery  
BigQuery Storage API를 사용하여 BigQuery에 저장된 테이블 데이터 읽기 지원  
BigQuery와 Hive와 같은 다른 시스템 간의 데이터를 결합하는 데 사용될 수 있습니다.  
The BigQuery connector can only access a `single GCP project`  
- Black Hole  
connector is designed for high performance testing of other components.  
- Cassandra  
아파치 카산드라에 저장된 데이터를 쿼리할 수 있게 해준다.  
Multi 지원  
- ClickHouse  
ClickHouse 커넥터를 사용하면 externalClickHouse 서버에서 테이블을 쿼리할 수 있습니다. 이것은 해당 서버의 데이터베이스에서 데이터를 쿼리하거나 ClickHouse 또는 기타 지원되는 데이터 소스에 액세스하는 다른 카탈로그의 다른 데이터와 결합하는 데 사용할 수 있습니다.
Multi 지원  
- Delta Lake  
Delta Lake 형식으로 저장된 데이터를 쿼리할 수 있습니다. 커넥터는 기본적으로 델타 레이크 거래 로그를 읽을 수 있으므로 외부 시스템이 데이터를 변경할 때 감지할 수 있습니다.  
You must configure a metastore for table metadata. If you are using a Hive metastore, hive.metastore.uri must be configured:
glue 를 이용해 메타스토어를 구성하는 경우 `hive.metastore=glue` 설정  
- Druid  
아파치 드루이드 데이터베이스를 쿼리할 수 있음.  
- Elasticsearch  
Elasticsearch 데이터에 액세스 가능  

- Google Sheets  
- Hive  
HDFS, Amazon S3 또는 S3 호환 시스템, Google Cloud Storage, Azure Storage 및 IBM Cloud Object Storage를 포함한 많은 분산 스토리지 시스템을 Hive 커넥터로 쿼리할 수 있습니다.
코디네이터와 모든 워커는 하이브 메타스토어와 스토리지 시스템에 대한 네트워크 액세스 권한이 있어야 합니다.  
Thrift 프로토콜을 사용한 하이브 메타스토어 액세스는 기본적으로 포트 9083을 사용합니다.
지원하는 데이터 파일 형식(일부 파일 형식은 카탈로그당 파일 형식 구성 속성을 사용하여 구성할 수 있습니다)  
  - ORC  
  - Parquet  
  - Avro  
  - RCText (ColumnarSerDe를 사용하는 RCFile)  
  - RCBinary (LazyBinaryColumnarSerDe를 사용하는 RCFile)  
  - SequenceFile  
  - JSON (org.apache.hive.hcatalog.data.JsonSerDe 사용)  
  - CSV (org.apache.hadoop.hive.serde2 사용. OpenCSVSerde)  
  - TextFile  
Multi 지원  
- Hudi  
후디 테이블을 쿼리할 수 있게 해준다.  
- Iceberg  
Iceberg 테이블 사양에 정의된 대로 Iceberg 형식으로 작성된 파일에 저장된 데이터를 쿼리할 수 있음.  
hive_metastore 설정 필요  
- Ignite  
Apache Ignitedatabase를 쿼리할 수 있음.  
Multi 지원  
- JMX  
Trino 노드들에서 자바 관리 확장(JMX) 정보를 쿼리할 수 있는 기능을 제공  
- Kafka  
아파치 카프카의 topic을 트리노의 테이블로 사용할 수 있게 해준다. 실시간 지원.  
단일 쿼리에서 동일한 테이블에 여러 번 액세스하면 이상한 동작이 발생할 수 있습니다(예: 자체 조인 수행).  
Multi 지원  
- Kinesis  
대규모의 분산된 데이터 스트림을 실시간으로 처리하기 위한 아마존의 클라우드 기반 서비스.  
스트림을 쿼리하려면 테이블 매핑이 필요합니다. 이러한 테이블 정의는 아마존 S3(선호)에서 수정되거나 각 트리노 노드의 로컬 디렉토리에 저장될 수 있습니다.  
- Kudu  
아파치 쿠두에서 데이터를 쿼리, 삽입 및 삭제할 수 있음.  
- Local File  
워커의 로컬 파일 시스템에 저장된 HTTP 요청 로그 파일을 쿼리  
- MariaDB  
MariaDB 데이터베이스에서 테이블을 쿼리하고 만들 수 있음.  
- Memory  
워커 노드의 메모리에 모든 데이터와 메타데이터를 저장하고 사용자 요청을 처리  
- MongoDB  
MongoDB 데이터 읽기 지원  
Multi 지원  
- MySQL  
Multi 지원  
- opensearch  
opensearch 데이터 읽기 지원  
- oracle  
multi 지원  
- phoenix  
- pinot  
- postgresql  
multi 지원  
- prometheus  
- redis  
multi 지원  
- redshift  
Multi 지원  
- SingleStore  
Multi 지원  
- SQL Server  
MS SQL Server  
Multi 지원  
- System  
현재 실행 중인 트리노 클러스터에 대한 정보와 지표를 제공  
- Thrift  
Thrift 프로토콜을 사용해 외부 스토리지와 연동될 수 있음. Trino Thrift 서비스의 구현 필요.  
Multi 지원  
- TPCDS  
Trino의 기능과 쿼리 구문을 테스트하는 데 사용. 성능 테스트용.  
- TPCH  
Trino의 기능과 쿼리 구문을 테스트하는 데 사용  

## Object Storage  

Connectors  

- Delta Lake  
- Hive  
- Hudi  
- Iceberg  

Native File System  

- Azure Storage  
- GCP Storage  
- S3 File System  

Legacy File System  

- Hive  
- Hive with Amazon S3  
- Hive with Azure Storage  
- Google Cloud Storage  
- Hive with IBM Cloude Object Storage  

Other  

- File System Cache  

## Functions And Operators

...  

## SQL Language

...  

## SQL statement syntax

...  

## SQL Routines

...  

## Developer Guide

### SPI Overview

트리노 플러그인을 구현할 때, 서비스 제공자 인터페이스(SPI)에 의해 정의된 인터페이스와 재정의 방법을 구현합니다.

플러그인을 통해 다음을 제공할 수 있습니다.  
커넥터,
블록 인코딩,
유형,
기능,
시스템 접근 제어,
그룹 제공자,
비밀번호 인증기,
헤더 인증기,
인증서 인증자,
이벤트 청취자,
자원 그룹 구성 관리자,
세션 속성 구성 관리자,
그리고 교환 관리자.

특히, 커넥터는 트리노에서 데이터 소스에 쿼리를 실행할 수 있도록 합니다.  

### Connector  

... 커넥터 개발과 관련해서 설명  

### HTTP Connector Example

...  

### JDBC Connector Example

이 단락에서는 `ConnectorMetadata`, `ConnectorRecordSetProvider` 같은 Trino SPI 서비스를 구현할 필요 없이 JDBC 드라이버를 사용하여 데이터 저장소에서 데이터를 읽기 위해 기본 `JdbcPlugin`을 확장하여 사용하는 방법을 설명한다.  

> 메모
> 단지 예시일 뿐이며, 매우 제한된 데이터 유형을 지원하며 `predicacte` 또는 다른 종류의 푸시다운과 같은 고급 기능을 지원하지 않습니다.

- 코드
JDBC 커넥터 예제는 Trino 소스 트리 내의 `trino-example-jdbc` 디렉토리에서 찾을 수 있습니다.  
- 플러그인 구현  
플러그인의 구현은 `JdbcPlugin` class 를 상속하고, `ExampleClientModule`을 사용한다.  
- 모듈  
`ExampleClient` class 는 `JDBC Connector`를 베이스로 사용하며, 커넥터 설정에서 지정된 JDBC URL을 기반으로 새로운 연결을 만드는 연결 공장을 제공합니다.  
- JdbcClient 구현  
JDBC 플러그인은 Trino SPI 호출을 JDBC API에 매핑합니다. 표 및 열 이름 읽기와 같은 작업은 JDBC에서 잘 정의되어 있으므로 기본 JDBC 플러그인은 대부분의 JDBC 드라이버에서 작동하는 방식으로 구현할 수 있습니다.  
기본적으로 구현되지 않는 동작 중 하나는 데이터를 읽고 쓸 때 데이터 유형을 매핑하는 것입니다. JDBC 커넥터 예제에서는 `BaseJdbcClient`를 확장하고 두 가지 메소드를 구현하는 exampleClient 클래스에서 JdbcClient 인터페이스를 구현합니다.  
- 컬럼 매핑
`toColumnMapping`은 커넥터에서 데이터를 읽을 때 사용됩니다. `ConnectorSession`, `Connection` 및 `JdbcTypeHandle`이 주어지면 일치하는 데이터 유형이 있는 경우 ColumnMapping을 반환합니다.  
열 매핑은 다음을 포함한다:  
트리노 타입,  
데이터 소스에서 실행할 JDBC 문을 준비할 때 쿼리 매개 변수 값을 설정하는 데 사용되는 쓰기 함수,  
그리고 JDBC 문 결과 집합에서 값을 읽고 내부 트리노 표현(예: 슬라이스)을 사용하여 반환하는 데 사용되는 읽기 함수.  
- 쓰기 매핑  
`toWriteMapping` is used when writing data to the connector. Given a ConnectorSession and a Trino type, it returns a WriteMapping.
  매핑은 다음을 포함한다:  
  - 데이터 유형 이름  
  - 쓰기 기능  

## Test

### 1. Docker 를 이용한 실행  

Standalone 형태로 컨테이너 하나만을 사용한 실행 방법  

- create directory to mount  
컨테이너에 마운트할 디렉토리 생성  

```shell
mkdir etc
mkdir data
```

- write node.properties  
[Node 설정 링크](https://trino.io/docs/current/installation/deployment.html#node-properties)  

```text
node.environment=production
node.id=ffffffff-ffff-ffff-ffff-ffffffffffff
node.data-dir=/var/trino/data
```

- write jvm.config  
[JVM 설정 링크](https://trino.io/docs/current/installation/deployment.html#jvm-config)  

```text
-server
-Xmx16G
-XX:InitialRAMPercentage=80
-XX:MaxRAMPercentage=80
-XX:G1HeapRegionSize=32M
-XX:+ExplicitGCInvokesConcurrent
-XX:+ExitOnOutOfMemoryError
-XX:+HeapDumpOnOutOfMemoryError
-XX:-OmitStackTraceInFastThrow
-XX:ReservedCodeCacheSize=512M
-XX:PerMethodRecompilationCutoff=10000
-XX:PerBytecodeRecompilationCutoff=10000
-Djdk.attach.allowAttachSelf=true
-Djdk.nio.maxCachedBufferSize=2000000
-Dfile.encoding=UTF-8
# Reduce starvation of threads by GClocker, recommend to set about the number of cpu cores (JDK-8192647)
-XX:+UnlockDiagnosticVMOptions
-XX:GCLockerRetryAllocationCount=32
```

- write config.properties  
[Config 설정 링크](https://trino.io/docs/current/installation/deployment.html#config-properties)  

```text
coordinator=true
node-scheduler.include-coordinator=true
http-server.http.port=8080
discovery.uri=http://[MyIP]:8080

# Catalog
catalog.management=dynamic
```

- run script  
실행 스크립트  

```shell
docker run --name trino -d -p 8080:8080 \
--volume $PWD/etc:/etc/trino \
--volume $PWD/data:/var/trino/data \
trinodb/trino
```

### 2. Dynamic Catalog 기능을 이용한 카탈로그(커넥터) 추가  

1. MinIO  

```text

```

select ptime, playerid, stint from postgre.test_schema.batting INNER JOIN mysql.

### 3. 데이터 조회
